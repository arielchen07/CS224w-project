{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import TransformerConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "from math import asin, cos, radians, sin, sqrt\n",
    "\n",
    "import osmium\n",
    "from osmium import osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8XKD1S0izdXv"
   },
   "outputs": [],
   "source": [
    "class GTN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, beta=True, heads=1):\n",
    "        super(GTN, self).__init__()\n",
    "\n",
    "        # The list of transormer conv layers for the each layer block.\n",
    "        self.num_layers = num_layers\n",
    "        conv_layers = [TransformerConv(input_dim, hidden_dim//heads, heads=heads, beta=beta)]\n",
    "        conv_layers += [TransformerConv(hidden_dim, hidden_dim//heads, heads=heads, beta=beta) for _ in range(num_layers - 2)]\n",
    "        # In the last layer, we will employ averaging for multi-head output by\n",
    "        # setting concat to True.\n",
    "        conv_layers.append(TransformerConv(hidden_dim, output_dim, heads=heads, beta=beta, concat=True))\n",
    "        self.convs = torch.nn.ModuleList(conv_layers)\n",
    "\n",
    "        # The list of layerNorm for each layer block.\n",
    "        norm_layers = [torch.nn.LayerNorm(hidden_dim) for _ in range(num_layers - 1)]\n",
    "        self.norms = torch.nn.ModuleList(norm_layers)\n",
    "\n",
    "        # Probability of an element getting zeroed.\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Resets the parameters of the convolutional and normalization layers,\n",
    "        ensuring they are re-initialized when needed.\n",
    "        \"\"\"\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for norm in self.norms:\n",
    "            norm.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        The input features are passed sequentially through the transformer\n",
    "        convolutional layers. After each convolutional layer (except the last),\n",
    "        the following operations are applied:\n",
    "        - Layer normalization (`LayerNorm`).\n",
    "        - ReLU activation function.\n",
    "        - Dropout for regularization.\n",
    "        The final layer is processed without layer normalization and ReLU\n",
    "        to average the multi-head results for the expected output.\n",
    "\n",
    "        Params:\n",
    "        - x: node features x\n",
    "        - edge_index: edge indices.\n",
    "\n",
    "        \"\"\"\n",
    "        for i in range(self.num_layers - 1):\n",
    "            # Construct the network as shown in the model architecture.\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = self.norms[i](x)\n",
    "            x = F.relu(x)\n",
    "            # By setting training to self.training, we will only apply dropout\n",
    "            # during model training.\n",
    "            x = F.dropout(x, p = self.dropout, training = self.training)\n",
    "\n",
    "        # Last layer, average multi-head output.\n",
    "        print(x.shape)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS_EARTH = 6371000\n",
    "\n",
    "def compute_distance(n1_longitude, n1_latitude, n2_longitude, n2_latitude) -> float:\n",
    "    lon1, lat1 = radians(n1_longitude), radians(n1_latitude)\n",
    "    lon2, lat2 = radians(n2_longitude), radians(n2_latitude)\n",
    "\n",
    "    # Haversine formula\n",
    "    deltaLon, deltaLat = lon2 - lon1, lat2 - lat1\n",
    "    haversine = (sin(deltaLat / 2) ** 2) + (cos(lat1) * cos(lat2)) * (\n",
    "        sin(deltaLon / 2) ** 2\n",
    "    )\n",
    "\n",
    "    # Return distance d (factor in radius of earth in meters)\n",
    "    return 2 * RADIUS_EARTH * asin(sqrt(haversine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(osmPath: str):\n",
    "    class MapCreationHandler(osmium.SimpleHandler):\n",
    "        def __init__(self) -> None:\n",
    "            super().__init__()\n",
    "            self.nodes = []\n",
    "            self.edges = [[], []]\n",
    "            self.edge_dist = []\n",
    "\n",
    "            self.node_id_to_idx = {}\n",
    "            self.idx_to_node_id = {}\n",
    "            self.id_counter = 0\n",
    "\n",
    "        def node(self, n: osm.Node) -> None:\n",
    "            self.nodes.append([n.location.lat, n.location.lon])\n",
    "            self.node_id_to_idx[n.id] = self.id_counter\n",
    "            self.idx_to_node_id[self.id_counter] = n.id\n",
    "            self.id_counter += 1\n",
    "\n",
    "        def way(self, w):\n",
    "            node_refs = [node.ref for node in w.nodes]\n",
    "\n",
    "            for i in range(len(node_refs) - 1):\n",
    "                node_start = node_refs[i]\n",
    "                node_end = node_refs[i + 1]\n",
    "                \n",
    "                node_1_idx = self.node_id_to_idx[node_start]\n",
    "                node_2_idx = self.node_id_to_idx[node_end]\n",
    "\n",
    "                self.edges[0].append(node_1_idx)\n",
    "                self.edges[1].append(node_2_idx)\n",
    "\n",
    "                node_1 = self.nodes[node_1_idx]\n",
    "                node_2 = self.nodes[node_2_idx]\n",
    "\n",
    "                n1_longitude, n1_latitude = node_1\n",
    "                n2_longitude, n2_latitude = node_2\n",
    "\n",
    "                dist = compute_distance(n1_longitude, n1_latitude, n2_longitude, n2_latitude)\n",
    "                self.edge_dist.append(dist)\n",
    "\n",
    "    mapCreator = MapCreationHandler()\n",
    "    mapCreator.apply_file(osmPath, locations=True)\n",
    "\n",
    "    x = torch.tensor(mapCreator.nodes, dtype=torch.float)\n",
    "    edge_index = torch.tensor(mapCreator.edges, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(mapCreator.edge_dist, dtype=torch.long).unsqueeze(1)\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  37.4340, -122.1725],\n",
      "        [  37.4342, -122.1726],\n",
      "        [  37.4344, -122.1724],\n",
      "        ...,\n",
      "        [  37.4312, -122.1713],\n",
      "        [  37.4312, -122.1712],\n",
      "        [  37.4314, -122.1710]])\n",
      "tensor([[13919, 13766, 13981,  ..., 23687, 23688, 23689],\n",
      "        [13766, 13981, 20493,  ..., 23006, 23689, 19361]])\n",
      "tensor([[ 8],\n",
      "        [ 7],\n",
      "        [52],\n",
      "        ...,\n",
      "        [ 2],\n",
      "        [12],\n",
      "        [10]])\n"
     ]
    }
   ],
   "source": [
    "graph = construct_graph(\"data/stanford.pbf\")\n",
    "print(graph.x)\n",
    "print(graph.edge_index)\n",
    "print(graph.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GTN(input_dim=2, hidden_dim=10, output_dim=10, num_layers=2,\n",
    "            dropout=0.1, beta=True, heads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23691, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4025, -0.1049, -0.4049,  ...,  0.1012, -0.3605, -0.0113],\n",
       "        [-0.7328, -0.0375, -0.6804,  ...,  0.4153, -0.1687, -0.0946],\n",
       "        [-0.6782, -0.0241, -0.6366,  ...,  0.4120, -0.0943, -0.1269],\n",
       "        ...,\n",
       "        [-0.6764, -0.0318, -0.7375,  ...,  0.3310, -0.1892, -0.1302],\n",
       "        [-0.6764, -0.0318, -0.7375,  ...,  0.3310, -0.1892, -0.1302],\n",
       "        [-0.3751, -0.2072, -0.3531,  ..., -0.0116, -0.4586, -0.0183]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(graph.x, graph.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmium\n",
    "import torch\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def construct_graph_order(osmPath: str, num_graphs=100, num_nodes=10):\n",
    "    class MapCreationHandler(osmium.SimpleHandler):\n",
    "        def __init__(self) -> None:\n",
    "            super().__init__()\n",
    "            self.nodes = []\n",
    "            self.edges = [[], []]\n",
    "            self.node_id_to_idx = {}\n",
    "            self.idx_to_node_id = {}\n",
    "            self.id_counter = 0\n",
    "\n",
    "        def node(self, n: osmium.osm.Node) -> None:\n",
    "            self.nodes.append([n.location.lat, n.location.lon])\n",
    "            self.node_id_to_idx[n.id] = self.id_counter\n",
    "            self.idx_to_node_id[self.id_counter] = n.id\n",
    "            self.id_counter += 1\n",
    "\n",
    "        def way(self, w):\n",
    "            node_refs = [node.ref for node in w.nodes]\n",
    "            for i in range(len(node_refs) - 1):\n",
    "                node_start = node_refs[i]\n",
    "                node_end = node_refs[i + 1]\n",
    "                if node_start in self.node_id_to_idx and node_end in self.node_id_to_idx:\n",
    "                    self.edges[0].append(self.node_id_to_idx[node_start])\n",
    "                    self.edges[1].append(self.node_id_to_idx[node_end])\n",
    "\n",
    "    mapCreator = MapCreationHandler()\n",
    "    mapCreator.apply_file(osmPath, locations=True)\n",
    "    all_nodes = torch.tensor(mapCreator.nodes, dtype=torch.float)\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for _ in range(num_graphs):\n",
    "        sampled_node_indices = random.sample(range(len(all_nodes)), num_nodes)\n",
    "        x = all_nodes[sampled_node_indices]\n",
    "        local_node_indices = {global_idx: local_idx for local_idx, global_idx in enumerate(sampled_node_indices)}\n",
    "        edge_index = torch.tensor([[local_node_indices[i], local_node_indices[i]] for i in sampled_node_indices], dtype=torch.long).t()\n",
    "        target_order = torch.arange(num_nodes, dtype=torch.long)\n",
    "\n",
    "        # Each datapoint has the following information: node information, edge information (partial or full?), and a target ordering\n",
    "        data = Data(x=x, edge_index=edge_index, target_order=target_order)\n",
    "        dataset.append(data)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the dataset\n",
    "dataset = construct_graph_order(\"data/stanford.pbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout, beta=True, heads=1):\n",
    "        super(GTN, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        conv_layers = [TransformerConv(input_dim, hidden_dim // heads, heads=heads, beta=beta)]\n",
    "        conv_layers += [TransformerConv(hidden_dim, hidden_dim // heads, heads=heads, beta=beta) for _ in range(num_layers - 2)]\n",
    "        conv_layers.append(TransformerConv(hidden_dim, output_dim, heads=heads, beta=beta, concat=True))\n",
    "        self.convs = torch.nn.ModuleList(conv_layers)\n",
    "\n",
    "        norm_layers = [torch.nn.LayerNorm(hidden_dim) for _ in range(num_layers - 1)]\n",
    "        self.norms = torch.nn.ModuleList(norm_layers)\n",
    "\n",
    "        # MLP for ordering scores\n",
    "        self.fc1 = torch.nn.Linear(output_dim, output_dim // 2)\n",
    "        self.fc2 = torch.nn.Linear(output_dim // 2, output_dim)\n",
    "        self.fc3 = torch.nn.Linear(output_dim, 1)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for norm in self.norms:\n",
    "            norm.reset_parameters()\n",
    "        for layer in [self.fc1, self.fc2, self.fc3]:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        if edge_index.size(1) == 0: \n",
    "            edge_index = torch.stack([torch.arange(x.size(0)), torch.arange(x.size(0))], dim=0).to(x.device)\n",
    "\n",
    "        # We should add additional information to the network\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = self.norms[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        scores = self.fc3(x).squeeze()  \n",
    "        \n",
    "        # Since this is an ordering problem, how should we compare our score to ground truth?\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 9.8694\n",
      "Epoch [2/20], Loss: 8.8360\n",
      "Epoch [3/20], Loss: 8.5482\n",
      "Epoch [4/20], Loss: 8.5193\n",
      "Epoch [5/20], Loss: 8.2930\n",
      "Epoch [6/20], Loss: 8.2387\n",
      "Epoch [7/20], Loss: 8.3118\n",
      "Epoch [8/20], Loss: 8.2731\n",
      "Epoch [9/20], Loss: 8.2657\n",
      "Epoch [10/20], Loss: 8.2668\n",
      "Epoch [11/20], Loss: 8.2569\n",
      "Epoch [12/20], Loss: 8.2494\n",
      "Epoch [13/20], Loss: 8.2760\n",
      "Epoch [14/20], Loss: 8.2552\n",
      "Epoch [15/20], Loss: 8.2524\n",
      "Epoch [16/20], Loss: 8.2500\n",
      "Epoch [17/20], Loss: 8.2500\n",
      "Epoch [18/20], Loss: 8.2500\n",
      "Epoch [19/20], Loss: 8.2500\n",
      "Epoch [20/20], Loss: 8.2500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Training parameters\n",
    "input_dim = 2      \n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "num_layers = 3\n",
    "dropout = 0.5\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20\n",
    "batch_size = 1 \n",
    "\n",
    "device = \"cpu\"\n",
    "model = GTN(input_dim, hidden_dim, output_dim, num_layers, dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def loss_(scores, target_order):\n",
    "   \n",
    "   # TODO: How should we handle the loss using score and target?\n",
    "    target_ranks = torch.arange(len(target_order), dtype=torch.float, device=scores.device)\n",
    "    ordered_scores = scores[target_order]\n",
    "    loss = F.mse_loss(ordered_scores, target_ranks)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(model, data_loader, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in data_loader:\n",
    "            batch = batch.to(device)  \n",
    "\n",
    "            scores = model(batch.x, batch.edge_index)\n",
    "            loss = loss_(scores, batch.target_order)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "train(model, data_loader, optimizer, num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
